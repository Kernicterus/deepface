{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "# Initialiser MediaPipe\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verified': False, 'distance': 0.460468570963124, 'threshold': 0.3, 'model': 'Facenet512', 'detector_backend': 'skip', 'similarity_metric': 'cosine', 'facial_areas': {'img1': {'x': 0, 'y': 0, 'w': 743, 'h': 697, 'left_eye': None, 'right_eye': None}, 'img2': {'x': 0, 'y': 0, 'w': 1464, 'h': 1464, 'left_eye': None, 'right_eye': None}}, 'time': 1.34}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = DeepFace.verify(\n",
    "    img1_path=\"faces_detected/ctedVtuMk81SSGTf.jpg\",\n",
    "    img2_path=\"faces_detected/BcRDRk8h5n.jpg\",\n",
    "    model_name=\"Facenet512\",\n",
    "    detector_backend=\"skip\",\n",
    "    distance_metric=\"cosine\"  # L2-normalized\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle de rotation du visage: -2.912233794912392\n"
     ]
    }
   ],
   "source": [
    "def estimate_rotation_angle(image_path):\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Détecter les points de repère faciaux\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # Extraire les coordonnées des points de repère clés\n",
    "        left_eye = np.array([landmarks[33].x, landmarks[33].y])\n",
    "        right_eye = np.array([landmarks[263].x, landmarks[263].y])\n",
    "\n",
    "        # Calculer l'angle de rotation\n",
    "        dY = right_eye[1] - left_eye[1]\n",
    "        dX = right_eye[0] - left_eye[0]\n",
    "        angle = np.degrees(np.arctan2(dY, dX))\n",
    "\n",
    "        return angle\n",
    "    else:\n",
    "        return \"Aucun visage détecté\"\n",
    "\n",
    "# Exemple d'utilisation\n",
    "image_path = \"faces_detected/face_2.jpg\"\n",
    "angle = estimate_rotation_angle(image_path)\n",
    "print(\"Angle de rotation du visage:\", angle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepface_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
