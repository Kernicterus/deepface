{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from deepface import DeepFace\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "# Initialiser MediaPipe\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasHistory' object has no attribute 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m result = \u001b[43mDeepFace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfaces_detected/face_1.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfaces_detected/face_2.jpg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mArcFace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmtcnn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# L2-normalized\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\deepface\\DeepFace.py:150\u001b[39m, in \u001b[36mverify\u001b[39m\u001b[34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mverify\u001b[39m(\n\u001b[32m     71\u001b[39m     img1_path: Union[\u001b[38;5;28mstr\u001b[39m, np.ndarray, List[\u001b[38;5;28mfloat\u001b[39m]],\n\u001b[32m     72\u001b[39m     img2_path: Union[\u001b[38;5;28mstr\u001b[39m, np.ndarray, List[\u001b[38;5;28mfloat\u001b[39m]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     83\u001b[39m ) -> Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m     84\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03m    Verify if an image pair represents the same person or different persons.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    147\u001b[39m \u001b[33;03m        - 'time' (float): Time taken for the verification process in seconds.\u001b[39;00m\n\u001b[32m    148\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mverification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[43m=\u001b[49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m=\u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\deepface\\modules\\verification.py:103\u001b[39m, in \u001b[36mverify\u001b[39m\u001b[34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03mVerify if an image pair represents the same person or different persons.\u001b[39;00m\n\u001b[32m     32\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     98\u001b[39m \u001b[33;03m    - 'time' (float): Time taken for the verification process in seconds.\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    101\u001b[39m tic = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m model: FacialRecognition = \u001b[43mmodeling\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfacial_recognition\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m dims = model.output_shape\n\u001b[32m    108\u001b[39m no_facial_area = {\n\u001b[32m    109\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    110\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mright_eye\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    115\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\deepface\\modules\\modeling.py:96\u001b[39m, in \u001b[36mbuild_model\u001b[39m\u001b[34m(task, model_name)\u001b[39m\n\u001b[32m     94\u001b[39m model = models[task].get(model_name)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     cached_models[task][model_name] = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid model_name passed - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\deepface\\models\\facial_recognition\\ArcFace.py:53\u001b[39m, in \u001b[36mArcFaceClient.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28mself\u001b[39m.model_name = \u001b[33m\"\u001b[39m\u001b[33mArcFace\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mself\u001b[39m.input_shape = (\u001b[32m112\u001b[39m, \u001b[32m112\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\deepface\\models\\facial_recognition\\ArcFace.py:67\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model\u001b[39m(\n\u001b[32m     60\u001b[39m     url=\u001b[33m\"\u001b[39m\u001b[33mhttps://github.com/serengil/deepface_models/releases/download/v1.0/arcface_weights.h5\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     61\u001b[39m ) -> Model:\n\u001b[32m     62\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[33;03m    Construct ArcFace model, download its weights and load\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[33;03m        model (Model)\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     base_model = \u001b[43mResNet34\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     inputs = base_model.inputs[\u001b[32m0\u001b[39m]\n\u001b[32m     69\u001b[39m     arcface_model = base_model.outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\deepface\\models\\facial_recognition\\ArcFace.py:115\u001b[39m, in \u001b[36mResNet34\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    112\u001b[39m x = PReLU(shared_axes=[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m], name=\u001b[33m\"\u001b[39m\u001b[33mconv1_prelu\u001b[39m\u001b[33m\"\u001b[39m)(x)\n\u001b[32m    113\u001b[39m x = stack_fn(x)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m model = \u001b[43mtraining\u001b[49m\u001b[43m.\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mResNet34\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[39m, in \u001b[36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m   result = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    206\u001b[39m   \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:116\u001b[39m, in \u001b[36mFunctional.__init__\u001b[39m\u001b[34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m generic_utils.validate_kwargs(kwargs, {})\n\u001b[32m    115\u001b[39m \u001b[38;5;28msuper\u001b[39m(Functional, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m(name=name, trainable=trainable)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_graph_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[39m, in \u001b[36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m   result = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    206\u001b[39m   \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:152\u001b[39m, in \u001b[36mFunctional._init_graph_network\u001b[39m\u001b[34m(self, inputs, outputs)\u001b[39m\n\u001b[32m    149\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[33m'\u001b[39m\u001b[33m_keras_history\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.outputs):\n\u001b[32m    150\u001b[39m     base_layer_utils.create_keras_history(\u001b[38;5;28mself\u001b[39m._nested_outputs)\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_graph_inputs_and_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# A Network does not create weights of its own, thus it is already\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# built.\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m.built = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\N_pro\\Anaconda3\\envs\\deepface_env\\Lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py:694\u001b[39m, in \u001b[36mFunctional._validate_graph_inputs_and_outputs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    688\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mInput tensors to a \u001b[39m\u001b[33m'\u001b[39m + cls_name + \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m +\n\u001b[32m    689\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33mmust come from `tf.keras.Input`. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    690\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33mReceived: \u001b[39m\u001b[33m'\u001b[39m + \u001b[38;5;28mstr\u001b[39m(x) +\n\u001b[32m    691\u001b[39m                    \u001b[33m'\u001b[39m\u001b[33m (missing previous layer metadata).\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    692\u001b[39m \u001b[38;5;66;03m# Check that x is an input tensor.\u001b[39;00m\n\u001b[32m    693\u001b[39m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m layer = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_keras_history\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlayer\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer._inbound_nodes) > \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    696\u001b[39m     layer._inbound_nodes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m layer._inbound_nodes[\u001b[32m0\u001b[39m].is_input):\n\u001b[32m    697\u001b[39m   cls_name = \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'KerasHistory' object has no attribute 'layer'"
     ]
    }
   ],
   "source": [
    "\n",
    "result = DeepFace.verify(\n",
    "    img1_path=\"faces_detected/face_1.jpg\",\n",
    "    img2_path=\"faces_detected/face_2.jpg\",\n",
    "    model_name=\"ArcFace\",\n",
    "    detector_backend=\"mtcnn\",\n",
    "    distance_metric=\"cosine\"  # L2-normalized\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle de rotation du visage: -2.912233794912392\n"
     ]
    }
   ],
   "source": [
    "def estimate_rotation_angle(image_path):\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Détecter les points de repère faciaux\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        landmarks = results.multi_face_landmarks[0].landmark\n",
    "\n",
    "        # Extraire les coordonnées des points de repère clés\n",
    "        left_eye = np.array([landmarks[33].x, landmarks[33].y])\n",
    "        right_eye = np.array([landmarks[263].x, landmarks[263].y])\n",
    "\n",
    "        # Calculer l'angle de rotation\n",
    "        dY = right_eye[1] - left_eye[1]\n",
    "        dX = right_eye[0] - left_eye[0]\n",
    "        angle = np.degrees(np.arctan2(dY, dX))\n",
    "\n",
    "        return angle\n",
    "    else:\n",
    "        return \"Aucun visage détecté\"\n",
    "\n",
    "# Exemple d'utilisation\n",
    "image_path = \"faces_detected/face_2.jpg\"\n",
    "angle = estimate_rotation_angle(image_path)\n",
    "print(\"Angle de rotation du visage:\", angle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepface_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
